{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5682797-473d-4c9d-91e4-ec9a03008235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directory above current directory to path\n",
    "import sys as SYS; SYS.path.insert(0, '..')\n",
    "\n",
    "# for saving\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import setup\n",
    "# setup.use_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba62db62-1b60-4671-bb6c-86f3a8c4652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import ( \n",
    "    measurements as measure,\n",
    "    density_matrix as DM,\n",
    "    simulation as sim,\n",
    "    orders,\n",
    "    order_rules,\n",
    "    random_unitary,\n",
    "    simulation)\n",
    "\n",
    "from Scripts import simulation_CLI as cleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f2f6f9-1688-4da5-a4e7-92834eb8385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "# Add directory above current directory to path\n",
    "import sys as SYS; SYS.path.insert(0, '../..')\n",
    "import h5py\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src import ket as ket\n",
    "from src import density_matrix as DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d840fda-a4fd-4384-b58d-92a7a7f3df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initializes the file. Don't need to do it after the first time\n",
    "import csv\n",
    "with open ('RunStats.csv', mode='w') as csv_file:\n",
    "    fieldnames = ['runtype_name', 'tz_mean','tz_std','MI_mean', 'MI_std', 'disp_mean','disp_std','clust_mean','clust_std', 'DeltaW_mean', 'DeltaW_std','DeltaW_persist_stat','DeltaW_persist_std']\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c5777-a7f5-43f9-8ab2-6b994a443f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the type of initial conditions and the number of qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2dba9856-3f25-447d-aeb2-1985cd4529d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label = \"pure\" #should come from this set {pure,therm,inhomov2,therm}\n",
    "num=12 # the number of qubits in the network\n",
    "num_seeds=100 # the number of seeds\n",
    "steps=499 # the number of steps in any one evolution\n",
    "denom = 15 # the angle denominator chosen for Haar Q unitary eg pi/15 then denom =15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596aa9c3-75cb-4fee-b6a0-5d97101004b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the large .hdf5 files have already been generated. If not, us any of the Data_Analysis_Big_Landsape notebooks to create them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4db6bd8b-8359-42af-b2e1-01d9483d625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata5 = dict(h5py.File(\"../data/unnati_submit_12_pure_strongmax/unnati_submit_12_pure_strongmax.hdf5\"))\n",
    "newdata2 = dict(h5py.File(\"../data/unnati_submit_12_pure_greedy/unnati_submit_12_pure_greedy.hdf5\"))\n",
    "newdata3 = dict(h5py.File(\"../data/unnati_submit_12_pure_mimic/unnati_submit_12_pure_mimic.hdf5\"))\n",
    "newdata4 = dict(h5py.File(\"../data/unnati_submit_12_pure_landmax/unnati_submit_12_pure_landmax.hdf5\"))\n",
    "newdata1 = dict(h5py.File(\"../data/unnati_submit_12_pure_random/unnati_submit_12_pure_random.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0b82b2-e796-40ea-abb8-88b6535f814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata5 = dict(h5py.File(\"../data/unnati_submit_12_therm_strong_max/unnati_submit_12_therm_strong_max.hdf5\"))\n",
    "newdata2 = dict(h5py.File(\"../data/unnati_submit_12_therm_greedy/unnati_submit_12_therm_greedy.hdf5\"))\n",
    "newdata3 = dict(h5py.File(\"../data/unnati_submit_12_therm_mimic/unnati_submit_12_therm_mimic.hdf5\"))\n",
    "newdata4 = dict(h5py.File(\"../data/unnati_submit_12_therm_landmax/unnati_submit_12_therm_landmax.hdf5\"))\n",
    "newdata1 = dict(h5py.File(\"../data/unnati_submit_12_therm_random/unnati_submit_12_therm_random.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1cbd894f-0314-4c27-a235-32bad5d6956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata5 = dict(h5py.File(\"../data/unnati_submit_12_inhomo_v1_strong_max/unnati_submit_12_inhomo_v1_strong_max.hdf5\"))\n",
    "newdata2 = dict(h5py.File(\"../data/unnati_submit_12_inhomo_v1_greedy/unnati_submit_12_inhomo_v1_greedy.hdf5\"))\n",
    "newdata3 = dict(h5py.File(\"../data/unnati_submit_12_inhomo_v1_mimic/unnati_submit_12_inhomo_v1_mimic.hdf5\"))\n",
    "newdata4 = dict(h5py.File(\"../data/unnati_submit_12_inhomo_v1_landmax/unnati_submit_12_inhomo_v1_landmax.hdf5\"))\n",
    "newdata1 = dict(h5py.File(\"../data/unnati_submit_12_inhomo_v1_random/unnati_submit_12_inhomo_v1_random.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32cd5d59-4ca7-44e1-a99a-6d7c91107419",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata1 = h5py.File(\"../data/random/random.hdf5\")\n",
    "newdata2 = h5py.File(\"../data/greedy/greedy.hdf5\")\n",
    "newdata3 = h5py.File(\"../data/mimic/mimic.hdf5\")\n",
    "newdata4 = h5py.File(\"../data/landscape_maximizes/landscape_maximizes.hdf5\")\n",
    "newdata5 = h5py.File(\"../data/strongest_maximizes/strongest_maximizes.hdf5\")\n",
    "# Initialize the file to write all results to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa11cf-4c1e-41ff-bf50-65a376b59a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The physics functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "503d49ae-ca5e-4749-a18d-572d91345829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pops(data, n_qubits, connectivity,update_rule):\n",
    "    #dimension 0 is each trial\n",
    "    #dimension 1 is each time step\n",
    "    #dimension 2 is each qubit\n",
    "    result = []\n",
    "    for trial in data[f'{n_qubits} qubits'][f'{connectivity} connectivity']['unitary energy subspace 1']:\n",
    "        seed = trial.split(' ')[-1]\n",
    "        dat = dict(data[f'{n_qubits} qubits'][f'{connectivity} connectivity']['unitary energy subspace 1'][f'unitary seed {seed}'][f'ordering seed {update_rule}']['pops'])\n",
    "        dat = {int(k.split('(')[0]): dat[k] for k in dat}\n",
    "        dat = np.array([np.array([dat[k][subkey][()] for subkey in sorted(dat[k])]) for k in sorted(dat)])\n",
    "        result.append(dat)\n",
    "    return(np.array(result))\n",
    "\n",
    "def get_2_qbit_dms(data, n_qubits, connectivity,update_rule):\n",
    "    basis = ket.canonical_basis(2)\n",
    "    #dimension 0 is each trial\n",
    "    #dimension 1 is each time step (recall that sampling step is 5 by default)\n",
    "    #dimension 2 is qubit pair\n",
    "    #dimension 3 and 4 is the 2 qubit density matrix\n",
    "    result = []\n",
    "    \n",
    "    def to_tuple(string):\n",
    "        tuple_elements = string.strip('()').split(',')\n",
    "        return tuple(int(elem.strip()) for elem in tuple_elements)\n",
    "\n",
    "    for trial in data[f'{n_qubits} qubits'][f'{connectivity} connectivity']['unitary energy subspace 1']:\n",
    "        seed = trial.split(' ')[-1]\n",
    "        dat = dict(data[f'{n_qubits} qubits'][f'{connectivity} connectivity']['unitary energy subspace 1'][f'unitary seed {seed}'][f'ordering seed {update_rule}']['two_qubit_dms'])\n",
    "        dat = {int(k.split('(')[0]): dat[k] for k in dat}\n",
    "        \n",
    "        dat = np.array([{to_tuple(subkey):DM.DensityMatrix(dat[k][subkey],basis) for subkey in sorted(dat[k])} for k in sorted(dat)])\n",
    "        result.append(dat)\n",
    "    return(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "58c4a126-70ff-4606-8411-2267f83da8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractable_work_of_one_trial(pops,trial):\n",
    "    return np.array([measure.extractable_work_of_each_qubit_from_pops(p) for p in pops[trial]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0302e96c-015c-4852-9680-4bd849722d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractable_work_of_all_trials(pops):\n",
    "    ext_work_all = []\n",
    "    for trial in range(100):\n",
    "        ext_work_all.append(extractable_work_of_one_trial(pops,trial))\n",
    "    return ext_work_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56030c-99a0-4038-a95d-0651f477143f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "64ed09e4-d0f5-4b2e-a632-d905b34630f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_in_ext_work(ext_work_one_trial):\n",
    "    return np.diff(ext_work_one_trial,axis = 0)\n",
    "\n",
    "def change_in_ext_work_all_trials(ext_work_all_trial):\n",
    "    change_in_ext_all =[]\n",
    "    for trial in range(100):\n",
    "        change_in_ext_all.append(np.diff(ext_work_all_trial[trial],axis = 0))\n",
    "    return change_in_ext_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cdf04121-1e3c-4ae4-b3f5-10da7321885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI of every pair\n",
    "def mutual_info_dicts(twoQdms, trial_index):\n",
    "    mutual_info_list = []\n",
    "    for time_step in twoQdms[trial_index]:\n",
    "        mutual_info_dict = {}\n",
    "        mutual_info = measure.mutual_information_of_every_pair_dict(time_step)\n",
    "        # Filter out values below the precision threshold\n",
    "        filtered_mutual_info = {k: v if v >= 1e-6 else 0 for k, v in mutual_info.items()}\n",
    "        # Update the mutual_info_dict with the filtered mutual info for the current time step\n",
    "        mutual_info_dict.update(filtered_mutual_info)\n",
    "        # Append the mutual_info_dict to the list\n",
    "        mutual_info_list.append(mutual_info_dict)\n",
    "    return mutual_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a5f7411d-bf16-4c15-ba0e-99802adbde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the two_point_dict function for each trial index\n",
    "# Get the list of dictionaries containing two point values for each time step\n",
    "def create_adjacency_matrix_two_dim(two_point_dict, num_nodes):\n",
    "    adjacency_matrix = [[0] * num_nodes for _ in range(num_nodes)]\n",
    "    for (node1, node2), two_point_value in two_point_dict.items():\n",
    "        adjacency_matrix[node1][node2] = two_point_value\n",
    "        adjacency_matrix[node2][node1] = two_point_value  # Assuming undirected graph\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2c76c70d-96e8-4c52-98bc-4bdabc97e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e7a20db3-10d4-4883-936f-24293e1fef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrices_list_two_dim(twoQdms, trial_index, num_nodes, two_point_dicts):\n",
    "    # Get the list of dictionaries containing mutual information values for each time step\n",
    "    two_point_dicts_list = two_point_dicts(twoQdms, trial_index)\n",
    "    # Create adjacency matrices for each time step\n",
    "    adjacency_matrices = []\n",
    "    for two_point_dict in two_point_dicts_list:\n",
    "        adj_matrix = create_adjacency_matrix_two_dim(two_point_dict, num_nodes)\n",
    "        adjacency_matrices.append(adj_matrix)\n",
    "    return adjacency_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "845ae33d-d1e4-4400-9525-fd8baa69fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates a giant list of adjacency matrices for each seed. Is a list of lists of 500 adjacency matrices each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b0d75bce-5be1-4372-957d-cb9481b31bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_adjacency_matrices(twoQdms, num_seeds, num_qubits, mutual_info_dicts):\n",
    "    # Initialize an empty list to store the adjacency matrices for each trial\n",
    "    all_trials_adjacency_matrices = []\n",
    "    \n",
    "    # Loop over each seed from 0 to num_seeds-1\n",
    "    for seed in range(num_seeds):\n",
    "        # Generate an empty list to store adjacency matrices for this trial\n",
    "        trial_matrices = []\n",
    "        \n",
    "        # Generate the adjacency matrix for the given seed\n",
    "        adj_matrix = adjacency_matrices_list_two_dim(twoQdms, seed, num_qubits, mutual_info_dicts)\n",
    "        \n",
    "        # Append each generated adjacency matrix to the trial-specific list\n",
    "        trial_matrices.append(adj_matrix)\n",
    "        \n",
    "        # Append the list of matrices for this trial to the overall list\n",
    "        all_trials_adjacency_matrices.append(trial_matrices)\n",
    "    \n",
    "    # Convert to a NumPy array if needed\n",
    "    all_trials_adjacency_matrices_array = np.array(all_trials_adjacency_matrices)\n",
    "    \n",
    "    return all_trials_adjacency_matrices_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53a01aee-2f1c-4b53-a71e-43527b0fb4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Mutual information on the network. This serves as a measure compared to the maximum mutual information that can develop on network\n",
    "def MItotal(MI_adj):\n",
    "    MI_adj_tot=[]\n",
    "    for i in range(len(MI_adj)):\n",
    "       MI_adj_tot.append(np.sum(MI_adj[i],axis=0))\n",
    "    return np.array(MI_adj_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8634ba96-75d8-4ddb-8586-13ac3cce5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering and disparity of network as a function of time: Can run with ensemble average set of adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "495a0c00-99d6-496b-b2b2-e443727645dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering Coefficient\n",
    "def clustering_coeff(adjacency_matrix_list):\n",
    "    C_list = []\n",
    "    #adjacency_matrix_list=np.array(adjacency_matrix_list)\n",
    "    for adj_mat in adjacency_matrix_list:\n",
    "        adj_mat=np.array(adj_mat)\n",
    "        M_sq = adj_mat@adj_mat\n",
    "        sum_of_M_sq = np.sum(M_sq)\n",
    "        M_cube = adj_mat@adj_mat@adj_mat\n",
    "        M_cube_trace = np.trace(M_cube)\n",
    "        C_list.append(M_cube_trace/sum_of_M_sq)\n",
    "    return np.array(C_list)\n",
    "\n",
    "#Disparity\n",
    "def disparity_function(adjacency_matrix_list, N):\n",
    "    D_list = []\n",
    "    for adj_mat in adjacency_matrix_list:\n",
    "        M_row_sum_squared = np.sum(adj_mat, axis=1)**2\n",
    "        M_row_sum_of_squared_elements = np.sum(adj_mat**2, axis=1)\n",
    "        # Check for zero division before performing division\n",
    "        Di = np.where(M_row_sum_squared != 0, M_row_sum_of_squared_elements / M_row_sum_squared, 0)\n",
    "        D_list.append(np.sum(Di) / N)\n",
    "    return np.array(D_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b68d7a-216f-485d-a043-3bb56668a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the the numerical value of shift per qubit map in one trial index i.e. one full time series of evolution\n",
    "\n",
    "def tz_two_q_dyns_map(pops_trial_index,denom): \n",
    "    tz = []\n",
    "    np.array(pops_trial_index)\n",
    "    for step_index in range(steps):\n",
    "        tzi =  np.sin(np.pi/denom)*np.sin(np.pi/denom) -2*(pops_trial_index[step_index + 1 ] - np.cos(np.pi / denom)*np.cos(np.pi / denom)* pops_trial_index[step_index])\n",
    "        tz.append(tzi)\n",
    "    return tz\n",
    "\n",
    "# Now put together the above to make the full list for all seeds\n",
    "    #dimension 0 is each trial\n",
    "    #dimension 1 is each time step\n",
    "    #dimension 2 is each qubit\n",
    "def tz_full_array(pops_all_trials):\n",
    "    tz_full_list=[]\n",
    "\n",
    "    for s in range(99):       \n",
    "        tz_full_list.append(tz_two_q_dyns_map(pops_all_trials[s],denom))\n",
    "\n",
    "    return np.array(tz_full_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01b3a134-3326-449e-aa49-d6d8b4a6b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The averaging procedures needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42d5a75f-2c93-48e5-99e3-20e8e5caebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns ensembled average one point dataset ie data should look like a full seed\n",
    "def late_time_average_of_list(list_one_trial):\n",
    "    late_time_data=np.delete(list_one_trial,slice(0,201),1)\n",
    "    late_time_data=np.delete(list_one_trial,slice(51,301),1)\n",
    "    ensemble_average = np.mean(late_time_data, axis=0)  # Shape (100, N)\n",
    "    return (ensemble_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a627c47-5826-48db-a0ad-600e42c1f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs late time avergaing (200-250 steps), then ensemble averages it for all trials, then takes the mean and std between qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbdb7250-a45e-48fa-ab93-d7a8a60695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use for DeltaWex and Tz\n",
    "#Returns late time value of one point measures for all qubits and then the mean and standard deviation between qubits\n",
    "def late_time_averages_one_point_all_seeds_between_q(datasets):\n",
    "    # Trim down the arrays to a segment of late time data\n",
    "    # Assuming datasets is a list of time steps (axis 0) for each qubit (axis 1), already averaged over seeds\n",
    "    \n",
    "        late_time_data=np.delete(datasets,slice(0,201),1)\n",
    "        late_time_data=np.delete(late_time_data,slice(51,301),1)\n",
    "    \n",
    "        # Take the average over the late time values\n",
    "        late_time_ave=np.mean(late_time_data,axis=1)\n",
    "    \n",
    "        # Take the average over seeds\n",
    "        late_time_seed_ave=np.mean(late_time_ave,axis=0)    \n",
    "        \n",
    "        # Finally, define the mean for each qubit, and the std deviation of qubits\n",
    "        qubit_mean=np.mean(late_time_seed_ave)\n",
    "        stddev_over_qubits=np.std(late_time_seed_ave)\n",
    "        return qubit_mean,stddev_over_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52604813-dd7c-47ac-ad57-9ca4195f2d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74ffaef-4fe1-437c-a11e-b107fa72a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns late time value of two point matrix\n",
    "def late_time_averages_two_point_one_seed(dataset):\n",
    "    # Trim down the arrays to a segment of late time data\n",
    "    # Assuming datasets is a list of time steps (axis 0) for each qubit (axis 1), already averaged over seeds\n",
    "    late_time_data=np.delete(late_time_data,slice(0,201),0)\n",
    "    late_time_data=np.delete(late_time_data,slice(51,301),0)\n",
    "\n",
    "    # Take the average over the late time values\n",
    "    late_time_ave=np.mean(late_time_data,axis=0)\n",
    "    return late_time_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a298a6e-e1c0-4837-942d-3e1679585378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns mean and std along each row, total along each row and std between total of each row\n",
    "def stats_for_a_matix(matrix):\n",
    "    mean_each_q=[]\n",
    "    for row in matrix:\n",
    "        mean_each_q.append(np.mean(row))\n",
    "    std_each_q=[]\n",
    "    for row in matrix:\n",
    "        std_each_q.append(np.std(row))\n",
    "    total_each_row=[]\n",
    "    for row in matrix:\n",
    "        total_each_q.append(np.total(row))\n",
    "    std_between_total_each_row=np.std(total_each_row)\n",
    "    return mean_each_q,std_each_q,total_each_q,std_between_total_each_row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0474327f-a873-4218-943d-2c79ebe88628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble average across 100 data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3d1adea-b5fc-4b92-9f4e-2b24baa8efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time average until time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d21d4a-4ff0-4c7a-b8a9-a03088e778d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_averaged_one_point_measures_at_t(dataset,t):\n",
    "    # Assuming dataset is list of 100 lists i.e. one trial\n",
    "    #stack datasets in 3D\n",
    "    # Take the ensemble average along the first axis (averaging over all datasets)\n",
    "    sum_till_t = np.sum(dataset[:t], axis=0)\n",
    "    time_average_t = (1/(t+1))*(sum_till_t)\n",
    "    return (time_average_t)\n",
    "\n",
    "def time_averaged_one_point_measures_matrix_full_sim(dataset):\n",
    "    # Take the ensemble average along the first axis (averaging over all datasets)\n",
    "    time_average=[]\n",
    "    for t in range(len(dataset)):\n",
    "        time_average.append(time_averaged_one_point_measures_at_t(dataset,t))\n",
    "    return (time_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ad5d516-62ca-4d2c-bb33-42f389cda53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns ensembled average one point dataset ie data should look like a full seed\n",
    "def ensemble_averaged_one_point_measures_mean_std(datasets):\n",
    "    # Assuming datasets is a list of 100 datasets, where each dataset is a 2D array of shape (100, N)\n",
    "    # Stack datasets into a 3D array\n",
    "    stacked_data = np.stack(datasets)  # Shape (100, 100, N)\n",
    "\n",
    "    # Take the ensemble average along the first axis (averaging over all datasets)\n",
    "    ensemble_average = np.mean(stacked_data, axis=0)  # Shape (100, N)\n",
    "\n",
    "    # Calculate the standard deviation along the first axis\n",
    "    ensemble_std = np.std(stacked_data, axis=0) \n",
    "    return (ensemble_average, ensemble_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "624bfe66-3dc9-4a60-9784-658b607f1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns ensembled average matrix from the datasets ie data should look like data for a full seed\n",
    "def ensemble_averaged_two_point_measures_mean(data):\n",
    "    ensemble_avg_list = []\n",
    "    # Loop through each time step\n",
    "    for t in range(499):\n",
    "        matrix_at_t_diff_trials=[]\n",
    "        for seed in range(99):\n",
    "            #matrix_at_t_diff_trials.append(data[seed][0][t])\n",
    "            matrix_at_t_diff_trials.append(data[seed][t])\n",
    "        # Calculate the average adjacency matrix for this time step\n",
    "        avg_matrix_at_t = np.mean(matrix_at_t_diff_trials, axis=0) \n",
    "        # Append the averaged matrix to the ensemble list\n",
    "        ensemble_avg_list.append(avg_matrix_at_t)\n",
    "    return ensemble_avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6235678-539d-4800-a9c1-523d50c6a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble averaged list of values ed use for getting ensembled average clustering disparity etc:\n",
    "def list_lists_of_values_measures(list_of_lists):\n",
    "    #Assuming each list in side the list is data from some measure on the landscape for the entire seed of length 500\n",
    "    #Example Clustering\n",
    "    mean_list = np.mean(list_of_lists,axis=1)\n",
    "    std_list = np.std(list_of_lists,axis=1)\n",
    "    return (mean_list, std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5bf9fa-3235-4dd5-93a5-d2dfd2cc3078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_average_late_time_mean_std_value(list_of_lists):\n",
    "    late_time_per_trial=[]\n",
    "    for l in list_of_lists:\n",
    "        late_time_per_trial.append(late_time_average_of_list(l))\n",
    "    mean_value = np.mean(late_time_per_trial,axis=0)\n",
    "    std_value = np.std(late_time_per_trial,axis=0)\n",
    "    return (mean_value,std_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f09622-936a-4c19-8bf5-4a5801bd4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, if the average over seeds has already been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "866a7ff6-786c-4193-9692-8a706de17e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_time_averages_ensemble_ave(datasets):\n",
    "    # Trim down the arrays to a segment of late time data\n",
    "    # Assuming datasets is a list of time steps (axis 0) for each qubit (axis 1), already averaged over seeds\n",
    "    late_time_data=np.delete(datasets,slice(0,201),0)\n",
    "    late_time_data=np.delete(late_time_data,slice(51,301),0)\n",
    "\n",
    "    # Take the average over the late time values\n",
    "    late_time_ave=np.mean(late_time_data,axis=0)\n",
    "    \n",
    "    # Finally, define the mean for each qubit, and the std deviation of qubits\n",
    "    qubit_mean=np.mean(late_time_ave)\n",
    "    stddev_over_qubits=np.std(late_time_ave)\n",
    "    return qubit_mean,stddev_over_qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5c77cae-2c3a-4c8b-bf22-3848863675c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to first define the adjacency matrices for each seed, where an average over late times has been done\n",
    "# This can then be used to compute dispartiy, clustering for each seed, and mean and std dev over seeds\n",
    "def late_time_averages_adj(datasets):\n",
    "    late_time_avg_adj_list = []\n",
    "    \n",
    "    # Trim down the arrays to a segment of late time data\n",
    "    # Assuming datasets is a list of 100 datasets (the seeds, axis 0), \n",
    "    # where each seed contains 500 steps (axis 1), and each step has a (num x num) (axis 2)\n",
    "    late_time_data=np.delete(datasets,slice(0,201),2)\n",
    "    late_time_data=np.delete(late_time_data,slice(51,301),2)\n",
    "\n",
    "    # Take the average over the late time values\n",
    "    late_time_ave=np.mean(late_time_data,axis=2)\n",
    "\n",
    "     # Append the late-time-averaged matrix for each seed to the list of adjacency matrices\n",
    "    for s in range(99):       \n",
    "        late_time_avg_adj_list.append(late_time_ave[s][0])\n",
    "    return late_time_avg_adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c4bda55-61f9-4240-a65a-aa031ded71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the computations requred to compute the MI, disp, and clust statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03731d12-40fc-4424-893f-6bcf94f5ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds the pops data for each rule, all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5ae92fc2-3224-4bed-a045-812977032d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num=12\n",
    "pops_random_c2 = get_pops(newdata1, num, \"c2_2local\", \"random\")\n",
    "pops_random_c4 = get_pops(newdata1, num, \"c4_2local\", \"random\")\n",
    "#pops_random_c5 = get_pops(newdata1, num, \"c5_2local\", \"random\")\n",
    "#pops_random_c6 = get_pops(newdata1, num, \"c6_2local\", \"random\")\n",
    "#pops_random_cn = get_pops(newdata1, num, \"cN_2local\", \"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b0c29ef5-4bc1-4956-99bc-f82d946461da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_greedy_c2 = get_pops(newdata2, num, \"c2_2local\", \"greedy\")\n",
    "pops_greedy_c4 = get_pops(newdata2, num, \"c4_2local\", \"greedy\")\n",
    "#pops_greedy_c5 = get_pops(newdata2, num, \"c5_2local\", \"greedy\")\n",
    "#pops_greedy_c6 = get_pops(newdata2, num, \"c6_2local\", \"greedy\")\n",
    "#pops_greedy_cn = get_pops(newdata2, num, \"cN_2local\", \"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d53847fa-81d6-404a-9e44-20c58196a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_mimic_c2 = get_pops(newdata3, num, \"c2_2local\", \"mimic\")\n",
    "pops_mimic_c4 = get_pops(newdata3, num, \"c4_2local\", \"mimic\")\n",
    "#pops_mimic_c5 = get_pops(newdata3, num, \"c5_2local\", \"mimic\")\n",
    "#pops_mimic_c6 = get_pops(newdata3, num, \"c6_2local\", \"mimic\")\n",
    "#pops_mimic_cn = get_pops(newdata3, num, \"cN_2local\", \"mimic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "49f4f4b4-bc8a-4ecf-9455-a1bb8b755142",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_landscape_maximizes_c2 = get_pops(newdata4, num, \"c2_2local\", \"landscape_maximizes\")\n",
    "pops_landscape_maximizes_c4 = get_pops(newdata4, num, \"c4_2local\", \"landscape_maximizes\")\n",
    "#pops_landscape_maximizes_c5 = get_pops(newdata4, num, \"c5_2local\", \"landscape_maximizes\")\n",
    "#pops_landscape_maximizes_c6 = get_pops(newdata4, num, \"c6_2local\", \"landscape_maximizes\")\n",
    "#pops_landscape_maximizes_cn = get_pops(newdata4, num, \"cN_2local\", \"landscape_maximizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "331a26c1-ad60-4da7-84f7-165acffa324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_strongest_maximizes_c2 = get_pops(newdata5, num, \"c2_2local\", \"strongest_maximizes\")\n",
    "pops_strongest_maximizes_c4 = get_pops(newdata5, num, \"c4_2local\", \"strongest_maximizes\")\n",
    "#pops_strongest_maximizes_c5 = get_pops(newdata5, num, \"c5_2local\", \"strongest_maximizes\")\n",
    "#pops_strongest_maximizes_c6 = get_pops(newdata5, num, \"c6_2local\", \"strongest_maximizes\")\n",
    "#pops_strongest_maximizes_cn = get_pops(newdata5, num, \"cN_2local\", \"strongest_maximizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "871119ac-172e-4c44-aa40-43ab034d77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_random_c2_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_random_c2)\n",
    "pops_random_c4_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_random_c4)\n",
    "#pops_random_c5_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_random_c5)\n",
    "#pops_random_c6_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_random_c6)\n",
    "#pops_random_cn_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_random_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "366d93a8-26bb-4ce3-9581-0ba295d26ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_greedy_c2_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_greedy_c2)\n",
    "pops_greedy_c4_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_greedy_c4)\n",
    "#pops_greedy_c5_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_greedy_c5)\n",
    "#pops_greedy_c6_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_greedy_c6)\n",
    "#pops_greedy_cn_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_greedy_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1334d1e2-bf79-4f9b-969f-70b4404970e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_mimic_c2_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_mimic_c2)\n",
    "pops_mimic_c4_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_mimic_c4)\n",
    "#pops_mimic_c5_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_mimic_c5)\n",
    "#pops_mimic_c6_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_mimic_c6)\n",
    "#pops_mimic_cn_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_mimic_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4e76e140-5cae-4ebf-a3bd-aa41de5f5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_landscape_maximizes_c2_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_landscape_maximizes_c2)\n",
    "pops_landscape_maximizes_c4_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_landscape_maximizes_c4)\n",
    "#pops_landscape_maximizes_c5_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_landscape_maximizes_c5)\n",
    "#pops_landscape_maximizes_c6_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_landscape_maximizes_c6)\n",
    "#pops_landscape_maximizes_cn_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_landscape_maximizes_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2c0f26f9-0e81-4081-8b9d-724409c99d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pops_strongest_maximizes_c2_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_strongest_maximizes_c2)\n",
    "pops_strongest_maximizes_c4_ens_avg = ensemble_averaged_one_point_measures_mean_std(pops_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a424bfc9-5ec4-4885-bccd-d48ee02924fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all twoqdms for C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5c7834b7-15a5-4667-9ff8-de096e807d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=12\n",
    "twoQdmsrandomc2 = get_2_qbit_dms(newdata1,size,\"c2_2local\",\"random\")\n",
    "twoQdmsgreedyc2 = get_2_qbit_dms(newdata2,size,\"c2_2local\",\"greedy\")\n",
    "twoQdmsmimicc2 = get_2_qbit_dms(newdata3,size,\"c2_2local\",\"mimic\")\n",
    "twoQdmslandscape_maxc2 = get_2_qbit_dms(newdata4,size,\"c2_2local\",\"landscape_maximizes\")\n",
    "twoQdmsstrongest_maxc2 = get_2_qbit_dms(newdata5,size,\"c2_2local\",\"strongest_maximizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "39c7cc1b-aab9-4f65-86a6-82946fedbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all twoqdms for C4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "97d913f9-540b-4291-861a-1ffa8bae0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoQdmsrandomc4 = get_2_qbit_dms(newdata1,size,\"c4_2local\",\"random\")\n",
    "twoQdmsgreedyc4 = get_2_qbit_dms(newdata2,size,\"c4_2local\",\"greedy\")\n",
    "twoQdmsmimicc4 = get_2_qbit_dms(newdata3,size,\"c4_2local\",\"mimic\")\n",
    "twoQdmslandscape_maxc4 = get_2_qbit_dms(newdata4,size,\"c4_2local\",\"landscape_maximizes\")\n",
    "twoQdmsstrongest_maxc4 = get_2_qbit_dms(newdata5,size,\"c4_2local\",\"strongest_maximizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "db1cf4d3-7532-4562-8ee4-5eeebfd546b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All extractable work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ccd3efe9-0685-4199-8850-43006e055113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  tr_1 = (1 - pop_1) * np.log(1 - pop_1) + (pop_1) * np.log(pop_1)\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:115: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  tr_1 = (1 - pop_1) * np.log(1 - pop_1) + (pop_1) * np.log(pop_1)\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:56: RuntimeWarning: invalid value encountered in log\n",
      "  return 1 / (np.log((1 - pop) / pop))\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:115: RuntimeWarning: invalid value encountered in log\n",
      "  tr_1 = (1 - pop_1) * np.log(1 - pop_1) + (pop_1) * np.log(pop_1)\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:64: RuntimeWarning: overflow encountered in exp\n",
      "  pop = 1 / (1 + np.exp(1 / T))\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  tr_2 = (1 - pop_1) * np.log(1 - pop_2) + (pop_1) * np.log(pop_2)\n"
     ]
    }
   ],
   "source": [
    "ext_work_all_random_c2 = np.array(extractable_work_of_all_trials(pops_random_c2))\n",
    "ext_work_all_greedy_c2 = np.array(extractable_work_of_all_trials(pops_greedy_c2))\n",
    "ext_work_all_mimic_c2 = np.array(extractable_work_of_all_trials(pops_mimic_c2))\n",
    "ext_work_all_landscape_maximizes_c2 = np.array(extractable_work_of_all_trials(pops_landscape_maximizes_c2))\n",
    "ext_work_all_strongest_maximizes_c2 = np.array(extractable_work_of_all_trials(pops_strongest_maximizes_c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a2d3df49-c1ff-4e10-a883-38a143940849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:116: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  tr_2 = (1 - pop_1) * np.log(1 - pop_2) + (pop_1) * np.log(pop_2)\n"
     ]
    }
   ],
   "source": [
    "ext_work_all_random_c4 = np.array(extractable_work_of_all_trials(pops_random_c4))\n",
    "ext_work_all_greedy_c4 = np.array(extractable_work_of_all_trials(pops_greedy_c4))\n",
    "ext_work_all_mimic_c4 = np.array(extractable_work_of_all_trials(pops_mimic_c4))\n",
    "ext_work_all_landscape_maximizes_c4 = np.array(extractable_work_of_all_trials(pops_landscape_maximizes_c4))\n",
    "ext_work_all_strongest_maximizes_c4 = np.array(extractable_work_of_all_trials(pops_strongest_maximizes_c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2bbb0c00-9c67-4632-bf36-4cca1ee826ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractable work of the ensembled average trial per connectivity per rule W(<p>) where p is the landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ad530c1c-a763-4279-a0c7-58dcaef66d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_work_of_ens_avg_random_c2 = extractable_work_of_one_trial(pops_random_c2_ens_avg,0)\n",
    "ext_work_of_ens_avg_random_c4 = extractable_work_of_one_trial(pops_random_c4_ens_avg,0)\n",
    "#ext_work_of_ens_avg_random_c5 = extractable_work_of_one_trial(pops_random_c5_ens_avg,0)\n",
    "##ext_work_of_ens_avg_random_c6 = extractable_work_of_one_trial(pops_random_c6_ens_avg,0)\n",
    "#ext_work_of_ens_avg_random_cn = extractable_work_of_one_trial(pops_random_cn_ens_avg,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a0abafdc-5003-4e39-b354-eb56a34ec653",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_work_of_ens_avg_greedy_c2 = extractable_work_of_one_trial(pops_random_c2_ens_avg,0)\n",
    "ext_work_of_ens_avg_greedy_c4 = extractable_work_of_one_trial(pops_random_c4_ens_avg,0)\n",
    "#ext_work_of_ens_avg_greedy_c5 = extractable_work_of_one_trial(pops_random_c5_ens_avg,0)\n",
    "#ext_work_of_ens_avg_greedy_c6 = extractable_work_of_one_trial(pops_random_c6_ens_avg,0)\n",
    "#ext_work_of_ens_avg_greedy_cn = extractable_work_of_one_trial(pops_random_cn_ens_avg,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f8d337d0-727a-47f2-a90b-152d1cc79739",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_work_of_ens_avg_mimic_c2 = extractable_work_of_one_trial(pops_mimic_c2_ens_avg,0)\n",
    "ext_work_of_ens_avg_mimic_c4 = extractable_work_of_one_trial(pops_mimic_c4_ens_avg,0)\n",
    "#ext_work_of_ens_avg_mimic_c5 = extractable_work_of_one_trial(pops_mimic_c5_ens_avg,0)\n",
    "#ext_work_of_ens_avg_mimic_c6 = extractable_work_of_one_trial(pops_mimic_c6_ens_avg,0)\n",
    "#ext_work_of_ens_avg_mimic_cn = extractable_work_of_one_trial(pops_mimic_cn_ens_avg,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5477d5f1-184b-4e25-8027-c35fb8a55635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ext_work_of_ens_avg_landscape_maximizes_c2 = extractable_work_of_one_trial(pops_landscape_maximizes_c2_ens_avg,0)\n",
    "ext_work_of_ens_avg_landscape_maximizes_c4 = extractable_work_of_one_trial(pops_landscape_maximizes_c4_ens_avg,0)\n",
    "#ext_work_of_ens_avg_landscape_maximizes_c5 = extractable_work_of_one_trial(pops_landscape_maximizes_c5_ens_avg,0)\n",
    "#ext_work_of_ens_avg_landscape_maximizes_c6 = extractable_work_of_one_trial(pops_landscape_maximizes_c6_ens_avg,0)\n",
    "#ext_work_of_ens_avg_landscape_maximizes_cn = extractable_work_of_one_trial(pops_landscape_maximizes_cn_ens_avg,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc172c8-9792-4060-8dd0-b19fd73dce19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a2560855-8bc4-487a-9969-eac8a023a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_work_of_ens_avg_strongest_maximizes_c2 = extractable_work_of_one_trial(pops_strongest_maximizes_c2_ens_avg,0)\n",
    "ext_work_of_ens_avg_strongest_maximizes_c4 = extractable_work_of_one_trial(pops_strongest_maximizes_c4_ens_avg,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0f477a43-ec14-448a-bf78-9eb2d4435057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:1496: RuntimeWarning: invalid value encountered in subtract\n",
      "  a = op(a[slice1], a[slice2])\n"
     ]
    }
   ],
   "source": [
    "#change in ext work all trials\n",
    "change_in_ext_work_all_random_c2 = change_in_ext_work_all_trials(ext_work_all_random_c2)\n",
    "change_in_ext_work_all_greedy_c2 = change_in_ext_work_all_trials(ext_work_all_greedy_c2)\n",
    "change_in_ext_work_all_mimic_c2 = change_in_ext_work_all_trials(ext_work_all_mimic_c2)\n",
    "change_in_ext_work_all_landscape_maximizes_c2 = change_in_ext_work_all_trials(ext_work_all_landscape_maximizes_c2)\n",
    "change_in_ext_work_all_strongest_maximizes_c2 = change_in_ext_work_all_trials(ext_work_all_strongest_maximizes_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3127285d-611e-4254-a3eb-5d957ab176a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_in_ext_work_all_random_c4 = change_in_ext_work_all_trials(ext_work_all_random_c4)\n",
    "change_in_ext_work_all_greedy_c4 = change_in_ext_work_all_trials(ext_work_all_greedy_c4)\n",
    "change_in_ext_work_all_mimic_c4 = change_in_ext_work_all_trials(ext_work_all_mimic_c4)\n",
    "change_in_ext_work_all_landscape_maximizes_c4 = change_in_ext_work_all_trials(ext_work_all_landscape_maximizes_c4)\n",
    "change_in_ext_work_all_strongest_maximizes_c4 = change_in_ext_work_all_trials(ext_work_all_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8a95887d-8430-446f-a4e3-ba0585ecb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and write out means and standard deviations for various statistics,\n",
    "# where the mean std dev is computed over qubits,\n",
    "# after each qubit is averaged over seeds, which are averaged over a ~50 step late-time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2a4fdc6b-ddc1-48ff-a659-2327192ea109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and standard deviation for extractable work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d0a8bd19-36ea-47c5-b82c-dd56a406a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/numpy/_core/_methods.py:135: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
     ]
    }
   ],
   "source": [
    "#THIS DOES IT FOR CHANGE IN EXTRACTABLE WORK\n",
    "W_stats_random_c2=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_random_c2)\n",
    "W_stats_random_c4=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_random_c4)\n",
    "W_stats_mimic_c2=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_mimic_c2)\n",
    "W_stats_mimic_c4=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_mimic_c4)\n",
    "W_stats_greedy_c2=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_greedy_c2)\n",
    "W_stats_greedy_c4=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_greedy_c4)\n",
    "W_stats_landscape_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_landscape_maximizes_c2)\n",
    "W_stats_landscape_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_landscape_maximizes_c4)\n",
    "W_stats_strongest_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_strongest_maximizes_c2)\n",
    "W_stats_strongest_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(change_in_ext_work_all_strongest_maximizes_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4cf50153-0b80-4637-a6b6-ce85a04f8a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(nan), np.float64(nan))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_stats_greedy_c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d66c2-59f1-4fb9-9c44-40edb201be60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7c5e762c-a734-401e-bee1-74be20fbaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CODE DOES IT FOR EXTRACTABLE WORK\n",
    "W_stats_random_c2=late_time_averages_one_point_all_seeds_between_q(ext_work_all_random_c2)\n",
    "W_stats_random_c4=late_time_averages_one_point_all_seeds_between_q(ext_work_all_random_c4)\n",
    "W_stats_mimic_c2=late_time_averages_one_point_all_seeds_between_q(ext_work_all_mimic_c2)\n",
    "W_stats_mimic_c4=late_time_averages_one_point_all_seeds_between_q(ext_work_all_mimic_c4)\n",
    "W_stats_greedy_c2=late_time_averages_one_point_all_seeds_between_q(ext_work_all_greedy_c2)\n",
    "W_stats_greedy_c4=late_time_averages_one_point_all_seeds_between_q(ext_work_all_greedy_c4)\n",
    "W_stats_landscape_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(ext_work_all_landscape_maximizes_c2)\n",
    "W_stats_landscape_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(ext_work_all_landscape_maximizes_c4)\n",
    "W_stats_strongest_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(ext_work_all_strongest_maximizes_c2)\n",
    "W_stats_strongest_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(ext_work_all_strongest_maximizes_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "223cf5ed-6b15-417b-8b39-a66a7920ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the computations for Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2154a00b-eac1-4a5a-a5ed-4f72901757c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of late-time-averaged (LTA) adjaceny matrices for all seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4177c3e3-fc4a-45dc-a107-e3ad580017dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:171: RuntimeWarning: divide by zero encountered in log\n",
      "  from_eigen = -np.sum(eigen_vals * np.log(eigen_vals))\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:171: RuntimeWarning: invalid value encountered in multiply\n",
      "  from_eigen = -np.sum(eigen_vals * np.log(eigen_vals))\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:182: RuntimeWarning: divide by zero encountered in log\n",
      "  -d4 * np.log(d4) +\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:182: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  -d4 * np.log(d4) +\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:183: RuntimeWarning: divide by zero encountered in log\n",
      "  - 0.5 * (b2 + c3 - np.sqrt(b2 ** 2 + 4 * b3 * c2 - 2 * b2 * c3 + c3 ** 2)) * np.log(\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:183: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  - 0.5 * (b2 + c3 - np.sqrt(b2 ** 2 + 4 * b3 * c2 - 2 * b2 * c3 + c3 ** 2)) * np.log(\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:185: RuntimeWarning: divide by zero encountered in log\n",
      "  - 0.5 * (b2 + c3 + np.sqrt(b2 ** 2 + 4 * b3 * c2 - 2 * b2 * c3 + c3 ** 2)) * np.log(\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:185: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  - 0.5 * (b2 + c3 + np.sqrt(b2 ** 2 + 4 * b3 * c2 - 2 * b2 * c3 + c3 ** 2)) * np.log(\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:181: RuntimeWarning: divide by zero encountered in log\n",
      "  -a1 * np.log(a1) +\n",
      "/Users/unnatiakhouri/Documents/GitHub/Qnibble/Notebooks/../src/measurements.py:181: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  -a1 * np.log(a1) +\n"
     ]
    }
   ],
   "source": [
    "num_qubits=12\n",
    "MI_adj_random_all_c2 = generate_all_adjacency_matrices(twoQdmsrandomc2, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_greedy_all_c2 = generate_all_adjacency_matrices(twoQdmsgreedyc2, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_mimic_all_c2 = generate_all_adjacency_matrices(twoQdmsmimicc2, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_landscape_maximizes_all_c2 = generate_all_adjacency_matrices(twoQdmslandscape_maxc2, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_strongest_maximizes_all_c2 = generate_all_adjacency_matrices(twoQdmsstrongest_maxc2, num_seeds, num_qubits, mutual_info_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a470ebf6-48c7-49e3-8ba8-06040db14727",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_adj_random_all_c4 = generate_all_adjacency_matrices(twoQdmsrandomc4, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_greedy_all_c4 = generate_all_adjacency_matrices(twoQdmsgreedyc4, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_mimic_all_c4 = generate_all_adjacency_matrices(twoQdmsmimicc4, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_landscape_maximizes_all_c4 = generate_all_adjacency_matrices(twoQdmslandscape_maxc4, num_seeds, num_qubits, mutual_info_dicts)\n",
    "MI_adj_strongest_maximizes_all_c4 = generate_all_adjacency_matrices(twoQdmsstrongest_maxc4, num_seeds, num_qubits, mutual_info_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b50fb691-5c45-4487-a512-c7400d9cb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTA_adj_random_c2=late_time_averages_adj(MI_adj_random_all_c2)\n",
    "LTA_adj_random_c4=late_time_averages_adj(MI_adj_random_all_c4)\n",
    "LTA_adj_greedy_c2=late_time_averages_adj(MI_adj_greedy_all_c2)\n",
    "LTA_adj_greedy_c4=late_time_averages_adj(MI_adj_greedy_all_c4)\n",
    "LTA_adj_mimic_c2=late_time_averages_adj(MI_adj_mimic_all_c2)\n",
    "LTA_adj_mimic_c4=late_time_averages_adj(MI_adj_mimic_all_c4)\n",
    "LTA_adj_landscape_maximizes_c2=late_time_averages_adj(MI_adj_landscape_maximizes_all_c2)\n",
    "LTA_adj_landscape_maximizes_c4=late_time_averages_adj(MI_adj_landscape_maximizes_all_c4)\n",
    "LTA_adj_strongest_maximizes_c2=late_time_averages_adj(MI_adj_strongest_maximizes_all_c2)\n",
    "LTA_adj_strongest_maximizes_c4=late_time_averages_adj(MI_adj_strongest_maximizes_all_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "099b6f55-61bd-40d6-9f71-874997ed9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "34a02a2b-f421-4cd7-a4ac-efbbf37b5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_random_c2=np.sum(MItotal(LTA_adj_random_c2),axis=1)\n",
    "MI_random_c4=np.sum(MItotal(LTA_adj_random_c4),axis=1)\n",
    "MI_greedy_c2=np.sum(MItotal(LTA_adj_greedy_c2),axis=1)\n",
    "MI_greedy_c4=np.sum(MItotal(LTA_adj_greedy_c4),axis=1)\n",
    "MI_mimic_c2=np.sum(MItotal(LTA_adj_mimic_c2),axis=1)\n",
    "MI_mimic_c4=np.sum(MItotal(LTA_adj_mimic_c4),axis=1)\n",
    "MI_landscape_maximizes_c2=np.sum(MItotal(LTA_adj_landscape_maximizes_c2),axis=1)\n",
    "MI_landscape_maximizes_c4=np.sum(MItotal(LTA_adj_landscape_maximizes_c4),axis=1)\n",
    "MI_strongest_maximizes_c2=np.sum(MItotal(LTA_adj_strongest_maximizes_c2),axis=1)\n",
    "MI_strongest_maximizes_c4=np.sum(MItotal(LTA_adj_strongest_maximizes_c4),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "64f5c8bf-0d67-4531-8d8b-43016fdf137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_stats_random_c2=(np.mean(MI_random_c2),np.std(MI_random_c2))\n",
    "MI_stats_random_c4=(np.mean(MI_random_c4),np.std(MI_random_c4))\n",
    "MI_stats_greedy_c2=(np.mean(MI_greedy_c2),np.std(MI_greedy_c2))\n",
    "MI_stats_greedy_c4=(np.mean(MI_greedy_c4),np.std(MI_greedy_c4))\n",
    "MI_stats_mimic_c2=(np.mean(MI_mimic_c2),np.std(MI_mimic_c2))\n",
    "MI_stats_mimic_c4=(np.mean(MI_mimic_c4),np.std(MI_mimic_c4))\n",
    "MI_stats_landscape_maximizes_c2=(np.mean(MI_landscape_maximizes_c2),np.std(MI_landscape_maximizes_c2))\n",
    "MI_stats_landscape_maximizes_c4=(np.mean(MI_landscape_maximizes_c4),np.std(MI_landscape_maximizes_c4))\n",
    "MI_stats_strongest_maximizes_c2=(np.mean(MI_strongest_maximizes_c2),np.std(MI_strongest_maximizes_c2))\n",
    "MI_stats_strongest_maximizes_c4=(np.mean(MI_strongest_maximizes_c4),np.std(MI_strongest_maximizes_c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bd54414b-233d-4d6f-b10f-2f09a59e2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "103f63dd-f330-4c36-9357-37947675671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_random_c2=clustering_coeff(LTA_adj_random_c2)\n",
    "clust_random_c4=clustering_coeff(LTA_adj_random_c4)\n",
    "clust_greedy_c2=clustering_coeff(LTA_adj_greedy_c2)\n",
    "clust_greedy_c4=clustering_coeff(LTA_adj_greedy_c4)\n",
    "clust_mimic_c2=clustering_coeff(LTA_adj_mimic_c2)\n",
    "clust_mimic_c4=clustering_coeff(LTA_adj_mimic_c4)\n",
    "clust_landscape_maximizes_c2=clustering_coeff(LTA_adj_landscape_maximizes_c2)\n",
    "clust_landscape_maximizes_c4=clustering_coeff(LTA_adj_landscape_maximizes_c4)\n",
    "clust_strongest_maximizes_c2=clustering_coeff(LTA_adj_strongest_maximizes_c2)\n",
    "clust_strongest_maximizes_c4=clustering_coeff(LTA_adj_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2772fb8a-e768-468a-92f4-09196c348148",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_stats_random_c2=(np.mean(clust_random_c2),np.std(clust_random_c2))\n",
    "clust_stats_random_c4=(np.mean(clust_random_c4),np.std(clust_random_c4))\n",
    "clust_stats_greedy_c2=(np.mean(clust_greedy_c2),np.std(clust_greedy_c2))\n",
    "clust_stats_greedy_c4=(np.mean(clust_greedy_c4),np.std(clust_greedy_c4))\n",
    "clust_stats_mimic_c2=(np.mean(clust_mimic_c2),np.std(clust_mimic_c2))\n",
    "clust_stats_mimic_c4=(np.mean(clust_mimic_c4),np.std(clust_mimic_c4))\n",
    "clust_stats_landscape_maximizes_c2=(np.mean(clust_landscape_maximizes_c2),np.std(clust_landscape_maximizes_c2))\n",
    "clust_stats_landscape_maximizes_c4=(np.mean(clust_landscape_maximizes_c4),np.std(clust_landscape_maximizes_c4))\n",
    "clust_stats_strongest_maximizes_c2=(np.mean(clust_landscape_maximizes_c2),np.std(clust_strongest_maximizes_c2))\n",
    "clust_stats_strongest_maximizes_c4=(np.mean(clust_landscape_maximizes_c4),np.std(clust_strongest_maximizes_c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5cb1458e-2708-41b5-85f8-cb71f1a598d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d639c14c-3a71-492c-a867-fffc3f5aa174",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_random_c2=disparity_function(LTA_adj_random_c2,num)\n",
    "disp_random_c4=disparity_function(LTA_adj_random_c4,num)\n",
    "disp_greedy_c2=disparity_function(LTA_adj_greedy_c2,num)\n",
    "disp_greedy_c4=disparity_function(LTA_adj_greedy_c4,num)\n",
    "disp_mimic_c2=disparity_function(LTA_adj_mimic_c2,num)\n",
    "disp_mimic_c4=disparity_function(LTA_adj_mimic_c4,num)\n",
    "disp_landscape_maximizes_c2=disparity_function(LTA_adj_landscape_maximizes_c2,num)\n",
    "disp_landscape_maximizes_c4=disparity_function(LTA_adj_landscape_maximizes_c4,num)\n",
    "disp_strongest_maximizes_c2=disparity_function(LTA_adj_strongest_maximizes_c2,num)\n",
    "disp_strongest_maximizes_c4=disparity_function(LTA_adj_strongest_maximizes_c4,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "12bbf4ed-88c5-43fb-8848-06378c82d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_stats_random_c2=(np.mean(disp_random_c2),np.std(disp_random_c2))\n",
    "disp_stats_random_c4=(np.mean(disp_random_c4),np.std(disp_random_c4))\n",
    "disp_stats_greedy_c2=(np.mean(disp_greedy_c2),np.std(disp_greedy_c2))\n",
    "disp_stats_greedy_c4=(np.mean(disp_greedy_c4),np.std(disp_greedy_c4))\n",
    "disp_stats_mimic_c2=(np.mean(disp_mimic_c2),np.std(disp_mimic_c2))\n",
    "disp_stats_mimic_c4=(np.mean(disp_mimic_c2),np.std(disp_mimic_c2))\n",
    "disp_stats_landscape_maximizes_c2=(np.mean(disp_landscape_maximizes_c2),np.std(disp_landscape_maximizes_c2))\n",
    "disp_stats_landscape_maximizes_c4=(np.mean(disp_landscape_maximizes_c4),np.std(disp_landscape_maximizes_c4))\n",
    "disp_stats_strongest_maximizes_c2=(np.mean(disp_strongest_maximizes_c2),np.std(disp_strongest_maximizes_c2))\n",
    "disp_stats_strongest_maximizes_c4=(np.mean(disp_strongest_maximizes_c4),np.std(disp_strongest_maximizes_c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "efc6f012-4ed9-40f7-a75e-25e55a9ada28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamical map component tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "49b64861-c295-4d22-8e12-3e3548accd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tzarray_random_c2=tz_full_array(pops_random_c2)\n",
    "tzarray_random_c4=tz_full_array(pops_random_c4)\n",
    "tzarray_greedy_c2=tz_full_array(pops_greedy_c2)\n",
    "tzarray_greedy_c4=tz_full_array(pops_greedy_c4)\n",
    "tzarray_mimic_c2=tz_full_array(pops_mimic_c2)\n",
    "tzarray_mimic_c4=tz_full_array(pops_mimic_c4)\n",
    "tzarray_landscape_maximizes_c2=tz_full_array(pops_landscape_maximizes_c2)\n",
    "tzarray_landscape_maximizes_c4=tz_full_array(pops_landscape_maximizes_c4)\n",
    "tzarray_strongest_maximizes_c2=tz_full_array(pops_strongest_maximizes_c2)\n",
    "tzarray_strongest_maximizes_c4=tz_full_array(pops_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8c7143ac-aed1-43f7-8935-f02bc2627de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tz_stats_random_c2=late_time_averages_one_point_all_seeds_between_q(tzarray_random_c2)\n",
    "tz_stats_random_c4=late_time_averages_one_point_all_seeds_between_q(tzarray_random_c4)\n",
    "tz_stats_greedy_c2=late_time_averages_one_point_all_seeds_between_q(tzarray_greedy_c2)\n",
    "tz_stats_greedy_c4=late_time_averages_one_point_all_seeds_between_q(tzarray_greedy_c4)\n",
    "tz_stats_mimic_c2=late_time_averages_one_point_all_seeds_between_q(tzarray_mimic_c2)\n",
    "tz_stats_mimic_c4=late_time_averages_one_point_all_seeds_between_q(tzarray_mimic_c4)\n",
    "tz_stats_landscape_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(tzarray_landscape_maximizes_c2)\n",
    "tz_stats_landscape_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(tzarray_landscape_maximizes_c4)\n",
    "tz_stats_strongest_maximizes_c2=late_time_averages_one_point_all_seeds_between_q(tzarray_strongest_maximizes_c2)\n",
    "tz_stats_strongest_maximizes_c4=late_time_averages_one_point_all_seeds_between_q(tzarray_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2eb9d574-36ec-4c9e-b12d-751825d8f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, write out all the stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fdb76c38-b0ff-4a01-bf5e-96fd7a7cd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('RunStats.csv', mode='a') as csv_file:\n",
    "    fieldnames = [\n",
    "        'runtype_name', 'tz_mean', 'tz_std', 'MI_mean', 'MI_std', 'disp_mean', 'disp_std', \n",
    "        'clust_mean', 'clust_std', 'DeltaW_mean', 'DeltaW_std', 'DeltaW_persist_stat', \n",
    "        'DeltaW_persist_std', 'Persist_skew_mean', 'Persist_skew_std', 'Persist_kurtosis_mean', \n",
    "        'Persist_kurtosis_std'\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    # Row 1\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R1Q8C2ICpure',\n",
    "        'tz_mean': tz_stats_random_c2[0], \n",
    "        'tz_std': tz_stats_random_c2[1],\n",
    "        'MI_mean': MI_stats_random_c2[0],\n",
    "        'MI_std': MI_stats_random_c2[1], \n",
    "        'DeltaW_mean': W_stats_random_c2[0],\n",
    "        'DeltaW_std': W_stats_random_c2[1],\n",
    "        'disp_mean': disp_stats_random_c2[0],\n",
    "        'disp_std': disp_stats_random_c2[1],\n",
    "        'clust_mean': clust_stats_random_c2[0],\n",
    "        'clust_std': clust_stats_random_c2[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_random_c2[0],\n",
    "        'DeltaW_persist_std': Persistence_data_random_c2[1],\n",
    "        'Persist_skew_mean': Persistence_data_random_c2[2],\n",
    "        'Persist_skew_std': Persistence_data_random_c2[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_random_c2[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_random_c2[5]\n",
    "    })\n",
    "\n",
    "    # Row 2\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R1Q8C4ICpure',\n",
    "        'tz_mean': tz_stats_random_c4[0], \n",
    "        'tz_std': tz_stats_random_c4[1],\n",
    "        'MI_mean': MI_stats_random_c4[0],\n",
    "        'MI_std': MI_stats_random_c4[1], \n",
    "        'DeltaW_mean': W_stats_random_c4[0],\n",
    "        'DeltaW_std': W_stats_random_c4[1],\n",
    "        'disp_mean': disp_stats_random_c4[0],\n",
    "        'disp_std': disp_stats_random_c4[1],\n",
    "        'clust_mean': clust_stats_random_c4[0],\n",
    "        'clust_std': clust_stats_random_c4[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_random_c4[0],\n",
    "        'DeltaW_persist_std': Persistence_data_random_c4[1],\n",
    "        'Persist_skew_mean': Persistence_data_random_c4[2],\n",
    "        'Persist_skew_std': Persistence_data_random_c4[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_random_c4[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_random_c4[5]\n",
    "    })\n",
    "\n",
    "    # Row 3\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R2Q8C2ICpure',\n",
    "        'tz_mean': tz_stats_greedy_c2[0], \n",
    "        'tz_std': tz_stats_greedy_c2[1],\n",
    "        'MI_mean': MI_stats_greedy_c2[0],\n",
    "        'MI_std': MI_stats_greedy_c2[1], \n",
    "        'DeltaW_mean': W_stats_greedy_c2[0],\n",
    "        'DeltaW_std': W_stats_greedy_c2[1],\n",
    "        'disp_mean': disp_stats_greedy_c2[0],\n",
    "        'disp_std': disp_stats_greedy_c2[1],\n",
    "        'clust_mean': clust_stats_greedy_c2[0],\n",
    "        'clust_std': clust_stats_greedy_c2[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_greedy_c2[0],\n",
    "        'DeltaW_persist_std': Persistence_data_greedy_c2[1],\n",
    "        'Persist_skew_mean': Persistence_data_greedy_c2[2],\n",
    "        'Persist_skew_std': Persistence_data_greedy_c2[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_greedy_c2[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_greedy_c2[5]\n",
    "    })\n",
    "\n",
    "    # Row 4\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R2Q8C4ICpure',\n",
    "        'tz_mean': tz_stats_greedy_c4[0], \n",
    "        'tz_std': tz_stats_greedy_c4[1],\n",
    "        'MI_mean': MI_stats_greedy_c4[0],\n",
    "        'MI_std': MI_stats_greedy_c4[1], \n",
    "        'DeltaW_mean': W_stats_greedy_c4[0],\n",
    "        'DeltaW_std': W_stats_greedy_c4[1],\n",
    "        'disp_mean': disp_stats_greedy_c4[0],\n",
    "        'disp_std': disp_stats_greedy_c4[1],\n",
    "        'clust_mean': clust_stats_greedy_c4[0],\n",
    "        'clust_std': clust_stats_greedy_c4[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_greedy_c4[0],\n",
    "        'DeltaW_persist_std': Persistence_data_greedy_c4[1],\n",
    "        'Persist_skew_mean': Persistence_data_greedy_c4[2],\n",
    "        'Persist_skew_std': Persistence_data_greedy_c4[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_greedy_c4[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_greedy_c4[5]\n",
    "    })\n",
    "\n",
    "    # Row 5\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R5Q8C2ICpure',\n",
    "        'tz_mean': tz_stats_mimic_c2[0], \n",
    "        'tz_std': tz_stats_mimic_c2[1],\n",
    "        'MI_mean': MI_stats_mimic_c2[0],\n",
    "        'MI_std': MI_stats_mimic_c2[1], \n",
    "        'DeltaW_mean': W_stats_mimic_c2[0],\n",
    "        'DeltaW_std': W_stats_mimic_c2[1],\n",
    "        'disp_mean': disp_stats_mimic_c2[0],\n",
    "        'disp_std': disp_stats_mimic_c2[1],\n",
    "        'clust_mean': clust_stats_mimic_c2[0],\n",
    "        'clust_std': clust_stats_mimic_c2[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_mimic_c2[0],\n",
    "        'DeltaW_persist_std': Persistence_data_mimic_c2[1],\n",
    "        'Persist_skew_mean': Persistence_data_mimic_c2[2],\n",
    "        'Persist_skew_std': Persistence_data_mimic_c2[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_mimic_c2[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_mimic_c2[5]\n",
    "    })\n",
    "\n",
    "    # Row 6\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R5Q8C4ICpure',\n",
    "        'tz_mean': tz_stats_mimic_c4[0], \n",
    "        'tz_std': tz_stats_mimic_c4[1],\n",
    "        'MI_mean': MI_stats_mimic_c4[0],\n",
    "        'MI_std': MI_stats_mimic_c4[1], \n",
    "        'DeltaW_mean': W_stats_mimic_c4[0],\n",
    "        'DeltaW_std': W_stats_mimic_c4[1],\n",
    "        'disp_mean': disp_stats_mimic_c4[0],\n",
    "        'disp_std': disp_stats_mimic_c4[1],\n",
    "        'clust_mean': clust_stats_mimic_c4[0],\n",
    "        'clust_std': clust_stats_mimic_c4[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_mimic_c4[0],\n",
    "        'DeltaW_persist_std': Persistence_data_mimic_c4[1],\n",
    "        'Persist_skew_mean': Persistence_data_mimic_c4[2],\n",
    "        'Persist_skew_std': Persistence_data_mimic_c4[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_mimic_c4[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_mimic_c4[5]\n",
    "    })\n",
    "\n",
    "    # Row 7\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R4Q8C2ICpure',\n",
    "        'tz_mean': tz_stats_landscape_maximizes_c2[0], \n",
    "        'tz_std': tz_stats_landscape_maximizes_c2[1],\n",
    "        'MI_mean': MI_stats_landscape_maximizes_c2[0],\n",
    "        'MI_std': MI_stats_landscape_maximizes_c2[1], \n",
    "        'DeltaW_mean': W_stats_landscape_maximizes_c2[0],\n",
    "        'DeltaW_std': W_stats_landscape_maximizes_c2[1],\n",
    "        'disp_mean': disp_stats_landscape_maximizes_c2[0],\n",
    "        'disp_std': disp_stats_landscape_maximizes_c2[1],\n",
    "        'clust_mean': clust_stats_landscape_maximizes_c2[0],\n",
    "        'clust_std': clust_stats_landscape_maximizes_c2[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_landscape_maximizes_c2[0],\n",
    "        'DeltaW_persist_std': Persistence_data_landscape_maximizes_c2[1],\n",
    "        'Persist_skew_mean': Persistence_data_landscape_maximizes_c2[2],\n",
    "        'Persist_skew_std': Persistence_data_landscape_maximizes_c2[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_landscape_maximizes_c2[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_landscape_maximizes_c2[5]\n",
    "    })\n",
    "\n",
    "    # Row 8\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R43Q8C4ICpure',\n",
    "        'tz_mean': tz_stats_landscape_maximizes_c4[0], \n",
    "        'tz_std': tz_stats_landscape_maximizes_c4[1],\n",
    "        'MI_mean': MI_stats_landscape_maximizes_c4[0],\n",
    "        'MI_std': MI_stats_landscape_maximizes_c4[1], \n",
    "        'DeltaW_mean': W_stats_landscape_maximizes_c4[0],\n",
    "        'DeltaW_std': W_stats_landscape_maximizes_c4[1],\n",
    "        'disp_mean': disp_stats_landscape_maximizes_c4[0],\n",
    "        'disp_std': disp_stats_landscape_maximizes_c4[1],\n",
    "        'clust_mean': clust_stats_landscape_maximizes_c4[0],\n",
    "        'clust_std': clust_stats_landscape_maximizes_c4[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_landscape_maximizes_c4[0],\n",
    "        'DeltaW_persist_std': Persistence_data_landscape_maximizes_c4[1],\n",
    "        'Persist_skew_mean': Persistence_data_landscape_maximizes_c4[2],\n",
    "        'Persist_skew_std': Persistence_data_landscape_maximizes_c4[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_landscape_maximizes_c4[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_landscape_maximizes_c4[5]\n",
    "    })\n",
    "\n",
    "    # Row 9\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R4Q8C2ICpure',\n",
    "        'tz_mean': tz_stats_strongest_maximizes_c2[0], \n",
    "        'tz_std': tz_stats_strongest_maximizes_c2[1],\n",
    "        'MI_mean': MI_stats_strongest_maximizes_c2[0],\n",
    "        'MI_std': MI_stats_strongest_maximizes_c2[1], \n",
    "        'DeltaW_mean': W_stats_strongest_maximizes_c2[0],\n",
    "        'DeltaW_std': W_stats_strongest_maximizes_c2[1],\n",
    "        'disp_mean': disp_stats_strongest_maximizes_c2[0],\n",
    "        'disp_std': disp_stats_strongest_maximizes_c2[1],\n",
    "        'clust_mean': clust_stats_strongest_maximizes_c2[0],\n",
    "        'clust_std': clust_stats_strongest_maximizes_c2[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_strongest_maximizes_c2[0],\n",
    "        'DeltaW_persist_std': Persistence_data_strongest_maximizes_c2[1],\n",
    "        'Persist_skew_mean': Persistence_data_strongest_maximizes_c2[2],\n",
    "        'Persist_skew_std': Persistence_data_strongest_maximizes_c2[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_strongest_maximizes_c2[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_strongest_maximizes_c2[5]\n",
    "    })\n",
    "\n",
    "    # Row 8\n",
    "    writer.writerow({\n",
    "        'runtype_name': 'R4Q8C4ICpure',\n",
    "        'tz_mean': tz_stats_strongest_maximizes_c4[0], \n",
    "        'tz_std': tz_stats_strongest_maximizes_c4[1],\n",
    "        'MI_mean': MI_stats_strongest_maximizes_c4[0],\n",
    "        'MI_std': MI_stats_strongest_maximizes_c4[1], \n",
    "        'DeltaW_mean': W_stats_strongest_maximizes_c4[0],\n",
    "        'DeltaW_std': W_stats_strongest_maximizes_c4[1],\n",
    "        'disp_mean': disp_stats_strongest_maximizes_c4[0],\n",
    "        'disp_std': disp_stats_strongest_maximizes_c4[1],\n",
    "        'clust_mean': clust_stats_strongest_maximizes_c4[0],\n",
    "        'clust_std': clust_stats_strongest_maximizes_c4[1],\n",
    "        'DeltaW_persist_stat': Persistence_data_strongest_maximizes_c4[0],\n",
    "        'DeltaW_persist_std': Persistence_data_strongest_maximizes_c4[1],\n",
    "        'Persist_skew_mean': Persistence_data_strongest_maximizes_c4[2],\n",
    "        'Persist_skew_std': Persistence_data_strongest_maximizes_c4[3],\n",
    "        'Persist_kurtosis_mean': Persistence_data_strongest_maximizes_c4[4],\n",
    "        'Persist_kurtosis_std': Persistence_data_strongest_maximizes_c4[5]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc7609ac-c7c2-40b6-88d4-3a9c1e9f5f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((np.float64(0.0014011697553602187), np.float64(4.3401722831722103e-05)),\n",
       " (np.float64(0.004475818445240242), np.float64(0.0007833036478061397)),\n",
       " (np.float64(0.0018134548287057906), np.float64(0.000190355394984272)),\n",
       " (np.float64(0.004242795894987534), np.float64(0.0008599429337025168)),\n",
       " (np.float64(0.002985021731884964), np.float64(0.0013396129661015083)),\n",
       " (np.float64(0.000877969330291428), np.float64(4.3446485121254166e-05)),\n",
       " (np.float64(0.004909774525812672), np.float64(0.0003764849739382052)),\n",
       " (np.float64(0.0013190902399404028), np.float64(3.210707050964729e-05)),\n",
       " (np.float64(0.006392694225459604), np.float64(0.0017624881930161781)),\n",
       " (np.float64(0.002985021731884964), np.float64(0.0013396129661015083)))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_stats_random_c2,W_stats_greedy_c2,W_stats_mimic_c2,W_stats_landscape_maximizes_c2,W_stats_strongest_maximizes_c2,W_stats_random_c4,W_stats_greedy_c4,W_stats_mimic_c4,W_stats_landscape_maximizes_c4,W_stats_strongest_maximizes_c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ab7c6e2f-6525-406a-bd29-a4b136474bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.13229287824981822, 0.013819297029398154),\n",
       " (0.11113541448022397, 0.006276879518026151),\n",
       " (0.14018283469701778, 0.045317020969064876),\n",
       " (0.11727387112490129, 0.025748098250654397),\n",
       " (0.13197104507535948, 0.02798024016956893),\n",
       " (0.11135647224556103, 0.006296290802734502),\n",
       " (0.14968552870924745, 0.05687353861071746),\n",
       " (0.11866571970270688, 0.028834019433634315),\n",
       " (0.16668791985714185, 0.043816468755098606),\n",
       " (0.11463256589405055, 0.016698533404454288))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tz_stats_random_c2,tz_stats_random_c4,tz_stats_greedy_c2,tz_stats_greedy_c4,tz_stats_mimic_c2,tz_stats_mimic_c4,tz_stats_landscape_maximizes_c2,tz_stats_landscape_maximizes_c4,tz_stats_strongest_maximizes_c2,tz_stats_strongest_maximizes_c4\n",
    "##clust_stats_random_c2,clust_stats_random_c4,clust_stats_greedy_c2,clust_stats_greedy_c4,clust_stats_mimic_c2,clust_stats_mimic_c4,clust_stats_landscape_maximizes_c2,clust_stats_landscape_maximizes_c4,clust_stats_strongest_maximizes_c2,clust_stats_strongest_maximizes_c4\n",
    "#disp_stats_random_c2,disp_stats_random_c4,disp_stats_greedy_c2,disp_stats_greedy_c4,disp_stats_mimic_c2,disp_stats_mimic_c4,disp_stats_landscape_maximizes_c2,disp_stats_landscape_maximizes_c4,disp_stats_strongest_maximizes_c2,disp_stats_strongest_maximizes_c4\n",
    "#MI_stats_random_c2,MI_stats_random_c4, MI_stats_greedy_c2,MI_stats_greedy_c4,MI_stats_mimic_c2,MI_stats_mimic_c4,MI_stats_landscape_maximizes_c2,MI_stats_landscape_maximizes_c4,MI_stats_strongest_maximizes_c2,MI_stats_strongest_maximizes_c4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe37827-41f7-4e86-8996-64a343fe5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Under progress\n",
    "#Functions for extractable work analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fdd2c15a-a060-4441-8950-4ab13aa15704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for extractable work analysis \n",
    "#Gives a list where first element is the total number of positive steps and the second is a list of when/length of the positive change\n",
    "def count_positive_steps(list_of_lists, index):\n",
    "    total_positive_steps = 0\n",
    "    consecutive_positive_steps = 0\n",
    "    consecutive_lengths = []  # List to store lengths of consecutive positive sequences\n",
    "    for lst in list_of_lists:\n",
    "        if lst[index] > 0:\n",
    "            total_positive_steps += 1\n",
    "            consecutive_positive_steps += 1\n",
    "        else:\n",
    "            consecutive_lengths.append(consecutive_positive_steps)  # Record length of consecutive positive sequence\n",
    "            consecutive_positive_steps = 0  # Reset consecutive count if value becomes non-positive\n",
    "            \n",
    "    # Add the last consecutive count if the list ends with a positive value\n",
    "    if consecutive_positive_steps > 0:\n",
    "        consecutive_lengths.append(consecutive_positive_steps)\n",
    "        \n",
    "    return total_positive_steps, consecutive_lengths\n",
    "\n",
    "def tally_elements(lst):\n",
    "    tally = {}\n",
    "    for element in lst:\n",
    "        tally[element] = tally.get(element, 0) + 1\n",
    "    return tally\n",
    "\n",
    "#Plots histogram using above tally dictionary\n",
    "def plot_histogram(ax, tally, label):\n",
    "    elements = list(tally.keys())\n",
    "    counts = list(tally.values())\n",
    "\n",
    "    ax.bar(elements, counts)\n",
    "    ax.set_xlabel('Element')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(label)\n",
    "    ax.legend(label)\n",
    "\n",
    "#Get the total number of positive steps per qubit on the network as a list\n",
    "def Num_steps_positive(change_in_ex_work):\n",
    "    Num_steps_positive=[]\n",
    "    for qubit_index in range(8):\n",
    "        Num_steps_positive.append(count_positive_steps(change_in_ex_work,qubit_index)[0])\n",
    "    return Num_steps_positive\n",
    "\n",
    "#Get the list of when positive changes occur per qubit on the network as a list\n",
    "def list_of_consecutive_positive_steps(change_in_ex_work):\n",
    "    sum=[0]\n",
    "    for qubit_id in range(8):\n",
    "        sum = sum+count_positive_steps(change_in_ex_work,qubit_id)[1]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc4a2d21-7205-4f79-9bdd-12e901f25bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the average length of interaval for which the qubit has positive change; does for each qubit and returns a list\n",
    "def average_time_step_Q_positive(num_qubits,changein_Wex):\n",
    "    average_time_positive = []\n",
    "    for qubit_index in range(num_qubits):\n",
    "        average_time_positive.append(np.mean(count_positive_steps(changein_Wex, qubit_index)[1]))\n",
    "    return average_time_positive\n",
    "    \n",
    "#takes in a dictionary\n",
    "def avg_time_step_positive(tally):\n",
    "    num=0\n",
    "    denom=0\n",
    "    for key,values in tally.items():\n",
    "        num = values*key+num\n",
    "        denom=values+denom\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67fcdade-518d-46ce-99b2-5d0dbd3ef4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get average of the cumulative positive change in extractable work since this is the value you can extract at any point from the landscape as resource\n",
    "def replace_negatives_with_zero(lst):\n",
    "    for sublist in lst:\n",
    "        for i in range(len(sublist)):\n",
    "            if sublist[i] < 0:\n",
    "                sublist[i] = 0\n",
    "    return lst\n",
    "\n",
    "def replace_consecutive_positives_with_cumulative_sum(list_of_lists):\n",
    "    lst = [list(column) for column in zip(*list_of_lists)]\n",
    "    for sublist in lst:\n",
    "        cumulative_sum = 0\n",
    "        consecutive_positive_count = 0\n",
    "        for i in range(len(sublist)):\n",
    "            if sublist[i] > 0:\n",
    "                cumulative_sum += sublist[i]\n",
    "                consecutive_positive_count += 1\n",
    "                if i == len(sublist) - 1 or sublist[i + 1] == 0:\n",
    "                    if consecutive_positive_count > 1:\n",
    "                        for j in range(i - consecutive_positive_count + 1, i + 1):\n",
    "                            sublist[j] = 0\n",
    "                        sublist[i] = cumulative_sum\n",
    "                    cumulative_sum = 0\n",
    "                    consecutive_positive_count = 0\n",
    "            else:\n",
    "                cumulative_sum = 0\n",
    "                consecutive_positive_count = 0\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9134bad0-0906-40a3-861b-0d9e9617f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_consec_positive_steps_no_zeros(change_in):\n",
    "    listt=[]\n",
    "    for ele in list_of_consecutive_positive_steps(change_in):\n",
    "        if ele != 0:\n",
    "            listt.append(ele)\n",
    "    return listt\n",
    "\n",
    "def consecutive_positives_with_cumulative_sum_no_zeores(change_in):\n",
    "    list2=[]\n",
    "    for ele in np.array(replace_consecutive_positives_with_cumulative_sum(replace_negatives_with_zero(change_in))).flatten():\n",
    "        if ele!=0:\n",
    "            list2.append(ele)\n",
    "    return list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "672b394b-4e22-4a00-91cb-7b41b6680f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_ex_resource_landscape(change_in_ex_work):\n",
    "    means=[]\n",
    "    for qubit in range(8):\n",
    "        means.append(np.mean(replace_consecutive_positives_with_cumulative_sum(replace_negatives_with_zero(change_in_ex_work))[qubit]))\n",
    "    return np.mean(means)\n",
    "\n",
    "def average_cumulative_Wex(num_qubits,changein_Wex):\n",
    "    average_time_positive = []\n",
    "    for qubit_index in range(num_qubits):\n",
    "        average_time_positive.append(np.mean(count_positive_steps(changein_Wex, qubit_index)[1]))\n",
    "    return average_time_positive\n",
    "    \n",
    "def total_wex(num_qubits,changein_Wex):\n",
    "    total_wex = []\n",
    "    for qubit_index in range(num_qubits):\n",
    "        changein_Wex[0:99,qubit_index]\n",
    "        total_wex.append(sum(changein_Wex[0:99,qubit_index]))\n",
    "    return total_wex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "43b3f926-3efb-4178-8ecc-9cd0633ae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_with_tally(tally_random,tally_greedy,tally_mimic,tally_landmax,tally_smax):\n",
    "    del tally_random[0]\n",
    "    del tally_greedy[0]\n",
    "    del tally_mimic[0]\n",
    "    del tally_landmax[0]\n",
    "    del tally_smax[0]\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
    "        \n",
    "    plot_histogram(axs[0], tally_random, 'R1 ')\n",
    "    plot_histogram(axs[1], tally_greedy, 'R2')\n",
    "    plot_histogram(axs[2], tally_mimic, 'R3')\n",
    "    plot_histogram(axs[3], tally_landmax, 'R4')\n",
    "    plot_histogram(axs[4], tally_smax, 'R5')\n",
    "\n",
    "    plt.savefig(f'histogram_freq_temp_var_{conn}_dataset_{label}_ens_avg_change_in_ext_work.png')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "be47e694-f6c6-41d2-a0b8-c5de9a21daff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ens_avg_change_in_ext_work_random_c2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m counts,bin_edges\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mhistogram(list_of_consec_positive_steps_no_zeros(\u001b[43mens_avg_change_in_ext_work_random_c2\u001b[49m),\u001b[38;5;241m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ens_avg_change_in_ext_work_random_c2' is not defined"
     ]
    }
   ],
   "source": [
    "counts,bin_edges=np.histogram(list_of_consec_positive_steps_no_zeros(ens_avg_change_in_ext_work_random_c2),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9068f70-2b89-4443-9784-296f56172ad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ens_avg_change_in_ext_work_random_c2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#C2 Histogram\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Num_steps_positive_random \u001b[38;5;241m=\u001b[39m Num_steps_positive(\u001b[43mens_avg_change_in_ext_work_random_c2\u001b[49m)\n\u001b[1;32m      3\u001b[0m Num_steps_positive_greedy \u001b[38;5;241m=\u001b[39m Num_steps_positive(ens_avg_change_in_ext_work_greedy_c2)\n\u001b[1;32m      4\u001b[0m Num_steps_positive_mimic \u001b[38;5;241m=\u001b[39m Num_steps_positive(ens_avg_change_in_ext_work_mimic_c2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ens_avg_change_in_ext_work_random_c2' is not defined"
     ]
    }
   ],
   "source": [
    "#C2 Histogram\n",
    "Num_steps_positive_random = Num_steps_positive(ens_avg_change_in_ext_work_random_c2)\n",
    "Num_steps_positive_greedy = Num_steps_positive(ens_avg_change_in_ext_work_greedy_c2)\n",
    "Num_steps_positive_mimic = Num_steps_positive(ens_avg_change_in_ext_work_mimic_c2)\n",
    "Num_steps_positive_landmax = Num_steps_positive(ens_avg_change_in_ext_work_landscape_maximizes_c2)\n",
    "Num_steps_positive_smax = Num_steps_positive(ens_avg_change_in_ext_work_strongest_maximizes_c2)\n",
    "\n",
    "tally_random=tally_elements(list_of_consecutive_positive_steps(ens_avg_change_in_ext_work_random_c2))\n",
    "tally_greedy=tally_elements(list_of_consecutive_positive_steps(ens_avg_change_in_ext_work_greedy_c2))\n",
    "tally_landmax=tally_elements(list_of_consecutive_positive_steps(ens_avg_change_in_ext_work_landscape_maximizes_c2))\n",
    "tally_mimic=tally_elements(list_of_consecutive_positive_steps(ens_avg_change_in_ext_work_mimic_c2))\n",
    "tally_smax=tally_elements(list_of_consecutive_positive_steps(ens_avg_change_in_ext_work_strongest_maximizes_c2))\n",
    "\n",
    "conn=\"c2\"\n",
    "plot_histogram_with_tally(tally_random,tally_greedy,tally_mimic,tally_landmax,tally_smax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bc1c9-f48f-437e-8f52-8c7eb17b6837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03b3411d-63fa-4b33-b7b9-c1b947aef97a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bin_edges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the histogram data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m hist_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbin_left_edge\u001b[39m\u001b[38;5;124m'\u001b[39m: bin_edges[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# Left edge of each bin\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbin_right_edge\u001b[39m\u001b[38;5;124m'\u001b[39m: bin_edges[\u001b[38;5;241m1\u001b[39m:],  \u001b[38;5;66;03m# Right edge of each bin\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m: counts                   \u001b[38;5;66;03m# Frequency of data in each bin\u001b[39;00m\n\u001b[1;32m      6\u001b[0m })\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Print the DataFrame\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(hist_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bin_edges' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the histogram data\n",
    "hist_df = pd.DataFrame({\n",
    "    'bin_left_edge': bin_edges[:-1],  # Left edge of each bin\n",
    "    'bin_right_edge': bin_edges[1:],  # Right edge of each bin\n",
    "    'count': counts                   # Frequency of data in each bin\n",
    "})\n",
    "# Print the DataFrame\n",
    "print(hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33b1eae1-c9c7-495a-ae47-93f462ac4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram stats:\n",
    "#Here we will compute, meadian, mean, mode, skewness, modality, kurtosis\n",
    "#Some additional terms are interval time frequency for each histogram\n",
    "def positive_interval_data(data):\n",
    "    #Assuming data list is list_of_consec_positive_steps_no_zeros(change_in_ext_work_ens_avg_random_c2)\n",
    "    #this will be for one seed\n",
    "    tally_dict = tally_elements(data)\n",
    "    min_val = int(np.floor(np.min(data)))  # Round down to nearest integer\n",
    "    max_val = int(np.ceil(np.max(data)))\n",
    "    bins = np.arange(min_val, max_val + 2)\n",
    "    counts=list(tally_dict.values())\n",
    "    bin_edges=categories = list(tally_dict.keys())\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    mode = categories[np.argmax(counts)]\n",
    "    std_dev = np.std(data)\n",
    "    data_skewness = skew(data)\n",
    "    data_kurtosis = kurtosis(data)\n",
    "    peak_interval = categories[np.argmax(counts)]*np.max(counts)\n",
    "\n",
    "    # Analyzing the shape of the histogram\n",
    "    # Symmetry check (comparing mean and median for skewness insight)\n",
    "    is_symmetric = np.isclose(mean, median)\n",
    "\n",
    "    return (mean,median,mode,std_dev,data_skewness,data_kurtosis,peak_interval)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d66e19d-c501-4cca-ad2c-6a32041a9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_interval_data_all_seed(list_of_lists):\n",
    "    stats_each_trial=[]\n",
    "    for l in list_of_lists:\n",
    "        stats_each_trial.append(positive_interval_data(l))\n",
    "    stats_each_trial=np.array(stats_each_trial)\n",
    "    peak_interval_all_trial=stats_each_trial[:,6]\n",
    "    mean_all_trial=stats_each_trial[:,0]\n",
    "    kurtosis_all_trials = stats_each_trial[:,5]\n",
    "    skewness_all_trials = stats_each_trial[:,4]\n",
    "    mean_peak = np.mean(peak_interval_all_trial,axis=0)\n",
    "    std_peak =np.std(peak_interval_all_trial,axis=0)\n",
    "    mean_kurtosis = np.mean(kurtosis_all_trials)\n",
    "    std_kurtosis = np.std(kurtosis_all_trials)\n",
    "    mean_skew = np.mean(skewness_all_trials)\n",
    "    std_skew = np.std(skewness_all_trials)\n",
    "    #similarly do for any other stats you want\n",
    "    return [mean_peak,std_peak,mean_skew,std_skew,mean_kurtosis,std_kurtosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4c32ef3-547d-44c5-8cb7-53b4eb0f221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of consecutive positive for all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "90adbed9-2afe-4b8f-b477-2f112ae5a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_consecutive_random_c2=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_random_c2:\n",
    "    list_of_lists_consecutive_random_c2.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_greedy_c2=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_greedy_c2:\n",
    "    list_of_lists_consecutive_greedy_c2.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_mimic_c2=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_mimic_c2:\n",
    "    list_of_lists_consecutive_mimic_c2.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_landscape_maximizes_c2=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_landscape_maximizes_c2:\n",
    "    list_of_lists_consecutive_landscape_maximizes_c2.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_strongest_maximizes_c2=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_strongest_maximizes_c2:\n",
    "    list_of_lists_consecutive_strongest_maximizes_c2.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e4f4c772-187f-4cb8-8d30-28f146df37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_consecutive_random_c4=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_random_c4:\n",
    "    list_of_lists_consecutive_random_c4.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_greedy_c4=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_greedy_c4:\n",
    "    list_of_lists_consecutive_greedy_c4.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_mimic_c4=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_mimic_c4:\n",
    "    list_of_lists_consecutive_mimic_c4.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_landscape_maximizes_c4=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_landscape_maximizes_c4:\n",
    "    list_of_lists_consecutive_landscape_maximizes_c4.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))\n",
    "\n",
    "list_of_lists_consecutive_strongest_maximizes_c4=[]\n",
    "for change_in_ext_work_one_trial in change_in_ext_work_all_strongest_maximizes_c4:\n",
    "    list_of_lists_consecutive_strongest_maximizes_c4.append(list_of_consec_positive_steps_no_zeros(change_in_ext_work_one_trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7939f633-d51e-4ffc-8027-3067c471cd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_of_lists_consecutive_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#tally_elements(list_of_lists_consecutive_random[1])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(tally_elements(\u001b[43mlist_of_lists_consecutive_random\u001b[49m[\u001b[38;5;241m15\u001b[39m])\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m      3\u001b[0m cas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tally_elements(list_of_lists_consecutive_random[\u001b[38;5;241m15\u001b[39m])\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      4\u001b[0m [c,cas]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_of_lists_consecutive_random' is not defined"
     ]
    }
   ],
   "source": [
    "#tally_elements(list_of_lists_consecutive_random[1])\n",
    "c=list(tally_elements(list_of_lists_consecutive_random[15]).values())\n",
    "cas = list(tally_elements(list_of_lists_consecutive_random[15]).keys())\n",
    "[c,cas]\n",
    "positive_interval_data(list_of_lists_consecutive_random[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9f9e726e-5e40-4ac9-976a-6bda3c8ac26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_peak_length, std_peak_length, mean_skew, std_skew, mean_kurtosis, std_kurtosis\n",
    "Persistence_data_random_c2=positive_interval_data_all_seed(list_of_lists_consecutive_random_c2)\n",
    "Persistence_data_random_c4=positive_interval_data_all_seed(list_of_lists_consecutive_random_c4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "077b82c8-285a-4616-bbfe-4045598d63a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(532.79),\n",
       " np.float64(217.99854563735053),\n",
       " np.float64(0.3774736562103202),\n",
       " np.float64(0.47383678894979553),\n",
       " np.float64(-0.29571586879291856),\n",
       " np.float64(1.0010322022905465)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Persistence_data_landscape_maximizes_c2=positive_interval_data_all_seed(list_of_lists_consecutive_landscape_maximizes_c2)\n",
    "Persistence_data_landscape_maximizes_c4=positive_interval_data_all_seed(list_of_lists_consecutive_landscape_maximizes_c4)\n",
    "Persistence_data_landscape_maximizes_c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ce532116-4443-43de-8a43-bb42bc879084",
   "metadata": {},
   "outputs": [],
   "source": [
    "Persistence_data_greedy_c2=positive_interval_data_all_seed(list_of_lists_consecutive_greedy_c2)\n",
    "Persistence_data_greedy_c4=positive_interval_data_all_seed(list_of_lists_consecutive_greedy_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8cbf0643-5500-462d-9920-8e7d09af66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Persistence_data_mimic_c2=positive_interval_data_all_seed(list_of_lists_consecutive_mimic_c2)\n",
    "Persistence_data_mimic_c4=positive_interval_data_all_seed(list_of_lists_consecutive_mimic_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c86be2c2-9845-4cca-bead-224d0369df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Persistence_data_strongest_maximizes_c2=positive_interval_data_all_seed(list_of_lists_consecutive_strongest_maximizes_c2)\n",
    "Persistence_data_strongest_maximizes_c4=positive_interval_data_all_seed(list_of_lists_consecutive_strongest_maximizes_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb5473-0dea-46e8-85c9-43bc6bc57dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d4f83-d99a-453d-b58d-ab88673a9925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a687a-8c69-4f5f-9a55-61b455390c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d16bf8-804e-4e18-ac59-ce6107e7739f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
